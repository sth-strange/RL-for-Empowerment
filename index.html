<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-M2BX14D2HX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-M2BX14D2HX');
</script>
    <meta charset="utf-8">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <link rel="stylesheet" href="stylesheets/style.css">
    <script src="javascripts/jquery-3.5.1.js" charset="utf-8"></script>
    <script src="javascripts/script.js" charset="utf-8"></script>
    <title>RL for Empowerment: Maximized Opportunities as a Proxy for Altruism</title>
    <meta name="viewport" content="width=device-width">
    <link rel="icon" type="image/x-icon" href="images/logo.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  </head>
  <body>
    <div class="cover">
      <img src="images/cover.png" alt="cover image" class="cover">
    </div>
    <div class="container">
      <div class="heading mobile_heading">RL for&nbsp;Empowerment: Maximized <br> Opportunities as&nbsp;a&nbsp;Proxy for&nbsp;Altruism</div>
      <div class="text grey_text sign">Alexandra Rybakova, Oleg Larikov, Slava Meriton, Vladislav Konoplitskij, Anna Samina, Yohanna Krasiwski</div>
      <div class="text grey_text mobile_sign">Alexandra Rybakova, Oleg Larikov, Slava Meriton, <br>Vladislav Konoplitskij, Anna Samina, Yohanna Krasiwski</div>
      <div class="flex">
        <div class="text_size">
          <div class="text first_text">How can we transform the&nbsp;intuitive notion of&nbsp;altruism into&nbsp;a&nbsp;formal framework for&nbsp;designing reinforcement learning (RL) agents? The&nbsp;immediate challenge is&nbsp;defining a&nbsp;reward function that&nbsp;promotes altruistic behavior.</div>
          <div class="text  paragraph">At&nbsp;the&nbsp;core, however, lies a&nbsp;deeper question: Can this&nbsp;formalized version of&nbsp;altruism serve as&nbsp;a&nbsp;reliable proxy? How far can this idea be pushed? We want to&nbsp;explore where it works, where it breaks down, and in&nbsp;which contexts altruistic proxy can or&nbsp;cannot be trusted to&nbsp;produce aligned behavior.</div>
          <div class="">
            <video class = 'mobile_video' width="100%" height="auto" controls>
              <source src="images/recording.mp4" type="video/mp4">
                <source src="images/recording.webm" type="video/webm">
                  Your browser does not support the video tag.
                </video>
          </div>
          <div class="flex button_flex ">
            <a href="https://docs.google.com/presentation/d/1hk7zFTGB_XUSdW7lUj2eHLIgumzkbm5AvrFNsOKDpUI/edit?usp=sharing" class="a_button">
            <div class="button active_button width_button">
              <div class="button_text">Slides</div>
            </div>
            </a>
            <div class="button button_distance non_active width_button">
              <div class="button_text non_active_text">Paper</div>
            </div>
            <div class="button button_distance non_active width_button">
              <div class="button_text non_active_text">Code</div>
            </div>
          </div>
        </div>
        <div class="distance">
          <div class="">
            <video class = 'video' width="100%" height="auto" controls>
              <source src="images/recording.mp4" type="video/mp4">
                <source src="images/recording.webm" type="video/webm">
                  Your browser does not support the video tag.
                </video>
          </div>
        </div>
      </div>
      <div class="subtitle">Introduction</div>
      <div class="text long_text">Our&nbsp;work builds on&nbsp;the&nbsp;Empowerment concept from&nbsp;work of&nbsp;Klyubin et al. “All&nbsp;Else Being Equal Be&nbsp;Empowered” which&nbsp;Du&nbsp;et&nbsp;al. later expanded in&nbsp;"AvE: Assistance via&nbsp;Empowerment". We also built on&nbsp;Franzmeyer et&nbsp;al.’s "Learning Altruistic Behaviours in&nbsp;Reinforcement Learning without External Rewards" with&nbsp;the&nbsp;introduction of&nbsp;the&nbsp;Choice metric. These approaches are&nbsp;grounded in&nbsp;the&nbsp;notion that, rather than&nbsp;achieving specific goals on&nbsp;our&nbsp;behalf, helpful AI should maximize our&nbsp;capacity to&nbsp;pursue a&nbsp;wide range of&nbsp;possibilities. The&nbsp;Choice metric reduces the&nbsp;need for&nbsp;an&nbsp;altruistic agent to&nbsp;possess perfect knowledge of&nbsp;its environment. It does this&nbsp;by&nbsp;defining the&nbsp;agent’s reward in&nbsp;terms of&nbsp;the&nbsp;number of&nbsp;possible states that&nbsp;its actions open&nbsp;up for&nbsp;the&nbsp;user. </div>
      <div class="text long_text paragraph">We are continuing this line of&nbsp;research, focusing on&nbsp;computation of&nbsp;the&nbsp;reward for&nbsp;opportunity maximizing agents. Specifically, we train so-called support agents using data from earlier steps of&nbsp;both support and target agent in&nbsp;the&nbsp;same episode. For&nbsp;example, if&nbsp;our&nbsp;planning horizon spans 10 steps, we defer calculating the&nbsp;reward for&nbsp;the&nbsp;first step until step 11, when we update the&nbsp;support agent's policy using snapshots of&nbsp;its and target agent's moves.</div>
      <div class="text long_text paragraph">In&nbsp;exploring different approaches to&nbsp;formalizing altruism, we believe it is crucial to&nbsp;recognize that&nbsp;even on&nbsp;a&nbsp;conceptual level altruism is&nbsp;not&nbsp;an&nbsp;end goal. It is a&nbsp;proxy. And like any&nbsp;proxy, it is vulnerable to&nbsp;Goodhart's law. The&nbsp;critical question driving our&nbsp;research is: How&nbsp;reliable is this&nbsp;proxy? What are the&nbsp;predictable failure modes we can replicate even&nbsp;with&nbsp;toy examples? As&nbsp;these are conceptual questions, we limit our&nbsp;investigation to&nbsp;a&nbsp;two-dimensional, discrete environment to&nbsp;facilitate clearer analysis of&nbsp;the&nbsp;underlying concepts.</div>
  <div class="subtitle">Work stages:</div>
  <div class="text long_text short_text">1. Formalization of&nbsp;the&nbsp;concept.</div>
  <div class="text grey_text short_text">Creating yet another reward function to&nbsp;incline RL agents toward altruistic behavior.</div>
  <div class="text long_text paragraph short_text">2. Performance Evaluation.</div>
  <div class="text grey_text short_text">Comparing the&nbsp;performance of&nbsp;altruistic agents with&nbsp;prior work to&nbsp;confirm that&nbsp;our&nbsp;approach performs on&nbsp;par&nbsp;with&nbsp;existing methods.</div>
  <div class="text long_text paragraph short_text">3. Failure Mode Analysis.</div>
  <div class="text grey_text short_text">Investigating the&nbsp;failure mode we’ve identified as&nbsp;the&nbsp;"trade-off scenario," where&nbsp;altruistic behavior conflicts with&nbsp;the&nbsp;objectives of&nbsp;the&nbsp;patron agent.</div>
  <div class="dotted"></div>
  <div class="text long_text paragraph short_text">4. Open Framework (coming soon).</div>
  <div class="text grey_text short_text">Developing an&nbsp;open framework that&nbsp;allows others to&nbsp;test their&nbsp;own hypotheses within&nbsp;this&nbsp;setup</div>
  <div class="subtitle">Join us!</div>
  <div class="text long_text paragraph">Originally, this work began as part of our final projects in
    <a href="https://aisafetyfundamentals.com/" class="custom_link">BlueDot Impact's AI Safety Fundamentals</a>
    and
    <a href="https://www.aisafetybook.com/virtual-course" class="custom_link">AI Safety, Ethics and Society Course by Center for AI Safety</a>, courses, but it has since evolved beyond courses timelines and the capacity of our small team. We believe that exploring altruism as a metric for useful agents can greatly benefit from diverse perspectives and encourage others to test their own hypotheses within our setup.</div>
    <div class="text long_text paragraph">We’re excited to&nbsp;announce that we’ll soon be opening this project to&nbsp;the&nbsp;community! If you have ideas or&nbsp;feedback, or&nbsp;if you’d like to&nbsp;stay updated on&nbsp;our&nbsp;progress, please reach out or&nbsp;subscribe for&nbsp;updates.</div>
    <div class="text long_text paragraph">Сlick the "Subscribe" button to receive notifications whenever we make changes, add new features, or release updates. Stay tuned to be among the first to know about our advancements!</div>
    <div class="text long_text paragraph">Contacts: six.of.proxies@gmail.com</div>
    <form id="subscribe-form">
      <div class="flex button_flex">
        <input type="email" id="email" name="email" placeholder="Enter your email" required class="input_mail">
        <div class="button_distance"></div>
        <button type="submit" class="button subscribe_button watch_button">
          <div class="button_text">Subscribe</div>
        </button>
      </div>
    </form>
    <div id="subscribe-message"></div>

  <div class="short_container">
    <div class="authors">
      <img src="images/authors.png" alt="authors image" class="authors">
    </div>
  </div>
  <div class="mobile_authors">
    <img src="images/authors.png" alt="mobile_authors image" class="mobile_authors">
  </div>
    </div>
    <div class="end"></div>
  </body>
</html>
